{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align: center;\">\n",
    "    Presentation of ShieldNet\n",
    "</h1>\n",
    "<p style=\"text-align: center\">\n",
    "    by Pascoli Massimiliano<br>\n",
    "    AAU id: 12138922<br>\n",
    "    e-mail: mapascoli@edu.aau.at<br>\n",
    "    date: 12/01/2022\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The learning task\n",
    "\n",
    "ShieldNet aspires to be an effective and efficient tool to detect Denial of Service (DoS) attacks, that would allow a human/machine to take countermeasures manually/automatically with low responsive times. Since the problem is not easy to resolve due to the wide taxonomy of DoS attack techniques, it is beneficial to specify the tuple $\\langle Task\\_to\\_perform, Performance\\_measure, Experience\\_data\\rangle$ that characterize my learning task for the machine learning problem I am going to face with.\n",
    "\n",
    "| ⚠️ WARNING                 |\n",
    "|:---------------------------|\n",
    "| Please note that every component of the learning task is split in two, this is to account for the **multiple** produced models: there were some technical difficulties with the multi-calss classifcation at first (attempted many different approaches) that got resolved in the end, exploiting the structure and workflow of the binary classification models produced during exploration (this was also a great opportunity to experiment with architectures, hyperparameters, data reduction techniques, ...). |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Task to perform\n",
    "\n",
    "DoS detection via packet flow aggregated metainformation, that is:<br>\n",
    "- the system must be able to distinguish if the connections flows (traditionally identified by tuple $\\langle \\text{source_ip, source_port, destination_ip, destination_port, protocol} \\rangle$) belong to a DoS attack or are just benign traffic. If the flow is malign, possibly know what kind of attack it is (multi-class classification);\n",
    "    + 12 classes present in the datasets used after the initial clean-up, representing 11 different DoS attacks techniques and the normal traffic class\n",
    "- there is an easier binary classification variant of the same problem which consists only in classifying between malicious and benign traffic flows starting from the same aggregated data mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Performance measure\n",
    "\n",
    "In general the system should be trained to minimize the number of miss-classifications, both in the binary and multi-class variant. It is particularly important a stong and correct discrimination between benign traffic and all the other malicious classes. If a flow is classified as malign, it should really be, it is less important that the attack technique is recognized correctly (nevertheless a correct classification can be very informative to apply further, more precise, countermeasures).\n",
    "\n",
    "In the table below are shown the specific metrics (in PyTorch) used to evaluate the goodness of a model after training:\n",
    "\n",
    "| BINARY | MULTI |\n",
    "|:-------|:------|\n",
    "| Per-class Accuracy | Per-class Accuracy |\n",
    "| Binary precision | Multiclass precision |\n",
    "| Binary recall | Multiclass recall |\n",
    "| Binary F1-score | Multiclass F1-score |\n",
    "| Binary Overall Accuracy | Multiclass Overall Accuracy |\n",
    "\n",
    "| ⚠️ WARNING                 |\n",
    "|:---------------------------|\n",
    "| Classes will be balanced after the preliminary data analysis. Technically I could have used accuracy as my only meaningful metric, but the other metrics are valid also with unbalanced problems.  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Reminder: metrics\n",
    "\n",
    "<center>\n",
    "    <img src=\".\\confusion_matrix.svg\" width=\"40%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| Metric | Meaning |\n",
    "|:--------|:------|\n",
    "| $$\\text{Precision or Positive Predicted Value (PPV)} = \\frac{TP}{TP + FP}$$ | Out of all *True/Positive/1* predicted values (i.e. class prediction *True/Positive/1*), how many of them were really *True/Positive/1* in %? |\n",
    "| $$\\text{Recall or True Positive Rate (TPR), Sensitivity, Hit Rate} = \\frac{TP}{TP + FN}$$ | Out of all samples that were really *True/Positive/1* (i.e. ground truth *True/Positive/1*), how many were predicted as *True/Positive/1* in %? |\n",
    "| $$\\text{F1-score} = \\frac{2}{\\frac{1}{TPR} + \\frac{1}{PPV}}$$ | Harmonic mean of Precision and Recall |\n",
    "| $$\\text{Accuracy (ACC)} = \\frac{TP+TN}{TP+TN+FP+FN}$$ | Out of all samples, how many were correctly classified in %? |\n",
    "| $$\\text{Per-class Accuracy}$$ | Correctly predicted for class $i$ (i.e. prediction equals ground truth) over total samples with same ground truth class $i$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Experience data\n",
    "\n",
    "In order to train the models, two different datasets were used:\n",
    "+ for the multi-class classification problem [CIC-DDoS2019](https://www.unb.ca/cic/datasets/ddos-2019.html) was used;\n",
    "+ for the binary classification problem [this](https://www.kaggle.com/datasets/devendra416/ddos-datasets) dataset was used, which is a balanced mixture of data coming from other very popular IDS datasets, in particular\n",
    "    - [CSE-CIC-IDS2018-AWS](https://www.unb.ca/cic/datasets/ids-2017.html);\n",
    "    - [CICIDS2017](https://www.unb.ca/cic/datasets/ids-2018.html);\n",
    "    - [CIC DoS dataset(2016)](https://www.unb.ca/cic/datasets/dos-dataset.html).\n",
    "\n",
    "Both datasets contain information of many generated internet traffic flows, labeled with *benign*, a specific attack name or general *DoS*. The data I used was generated with the same learning task in mind: it was recorded on a test network diverse enough to include several possible attack devices and victim devices. \n",
    "The data was recorded capturing raw packets using [libpcap](https://www.tcpdump.org/) (OS independent library that is available for use in many programming languages) available with *tcpdump* utility and then, using [CICFlowMeter](https://www.unb.ca/cic/research/applications.html) some aggregated metrics were computed (please refer to [this page](https://www.unb.ca/cic/datasets/ids-2018.html) to know what metrics this tool can calculate given raw packets in pcap standard). Around 80 of these metrics were chosen to be present in the datasets and not all of them are useful for my goal, nor for every model proposed in the Implementation section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examining the datasets\n",
    "\n",
    "In this section, my goal is to understand the data, its organization and representation, in order to get ready for learning.\n",
    "\n",
    "In the end we would like to have more or less **balanced** datasets, this is to help learning a correct inference model/function, for both the multi-class classification task (MCCT) and binary classification task (BCT). Furthermore, it is important for the purposes of training that the data we provide to the ANN is **not malformed or missing** and is **numeric**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MCCT dataset analysis\n",
    "\n",
    "The schematic structure of CIC-DDoS2019 dataset is the following:\n",
    "\n",
    "<center>\n",
    "    <img src=\"./CIC2019_struct.JPG\" width=\"40%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As you can see, the raw dataset is difficult to use for at least 4 reasons:\n",
    "\n",
    "1. BENIGN class is not separated in its own file, but it is mixed with all the other classes in very csv;\n",
    "2. Not all classes present in the training part are present also in the test part (and vice-versa): the training/test split suggestion is useless for our task, might as well ignore it completely;\n",
    "3. Classes are far from balanced;\n",
    "4. The size of every csv listed ranges from 0.1GB to 8.7GB given a total of 28.9GB: impossible to load all dataset at one or only training/test part to have a more or less complete view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Classes distribution of CIC-DDoS2019 in detail for point 3 presented previously (training part left, test part right):\n",
    "\n",
    "<center>\n",
    "    <img src=\".\\CIC2019_distr.png\" width=\"70%\">\n",
    "</center>\n",
    "\n",
    "The number of samples for each class is completely out of scale with respect to others.\n",
    "\n",
    "WebDDoS and Portmap traffic samples are almost non-existant compared to BENIGN class, and Portscan is technically not a DoS technique, but a service and port probing tool...\n",
    "\n",
    "<p style=\"text-align: center\">WHAT DO WE DO?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Solution to MCCT dataset\n",
    "\n",
    "Given the dataset in the form described and since my computing power is limited, the solution implemented is to reconstruct a single, unified, balanced dataset cutting down in a **fair** manner all oversized classes, dropping Portmap and WebDDoS classes entirely. Below, a brief data transformation schema is reported:\n",
    "\n",
    "<center>\n",
    "    <img src=\".\\data_analysis.svg\" width=\"100%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The final result is a csv file in which samples belonging to every class are cut down to the number of samples that the least numerous class has.\n",
    "\n",
    "As a collateral product, not only the dataset has the desiderable properties described, but also is only 0.43GB. This allows me to load all data to main memory at once as a single DataFrame (empirically main memory occupied by DataFrame object is two times the csv file size).\n",
    "\n",
    "Every class now has 112731 samples, bringing the total number of samples to $112731 \\cdot 12 = 1352772$ as shown below:\n",
    "\n",
    "<center>\n",
    "    <img src=\".\\CIC2019_distr_total.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Literature overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
